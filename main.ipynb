{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2e013b1",
   "metadata": {},
   "source": [
    "## Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb14fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81a64c4",
   "metadata": {},
   "source": [
    "Document Loading..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_loader = TextLoader(\"./data/hello.txt\")\n",
    "text_documents = text_loader.load()\n",
    "text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyMuPDFLoader(\"./data/Presentation.pdf\")\n",
    "pdf_documents = pdf_loader.load()\n",
    "print(f\"Loaded {len(pdf_documents)} PDF documents.\")\n",
    "pdf_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6222c77",
   "metadata": {},
   "source": [
    "Spliting into Chunks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6684c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents,chunk_size=1000,chunk_overlap=200):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(pdf_documents)\n",
    "    print(f\"Split {len(pdf_documents)} documents into {len(split_docs)} chunks\")\n",
    "\n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk:\")\n",
    "        print(f\"Content: {split_docs[0].page_content[:200]}...\")\n",
    "        print(f\"Metadata: {split_docs[0].metadata}\")\n",
    "    \n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77180d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_documents(pdf_documents)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2e5be",
   "metadata": {},
   "source": [
    "Embedding Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfad40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingManager:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "        try:\n",
    "            print(f\"Loading model '{self.model_name}'...\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model '{self.model_name}' loaded successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model '{self.model_name}': {e}\")\n",
    "\n",
    "    def embed_texts(self, texts: List[str]) -> np.ndarray:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model is not loaded.\")\n",
    "        \n",
    "        embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings for {len(texts)} texts.\")\n",
    "        return embeddings\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f96df",
   "metadata": {},
   "source": [
    "Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a35b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, collection_name: str = \"academic_documents\", persist_directory: str = \"./data/vector_store\"):\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = persist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._init_store()\n",
    "    \n",
    "    def _init_store(self):\n",
    "        try:\n",
    "            print(\"Initializing ChromaDB client...\")\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "            self.collection = self.client.get_or_create_collection(name=self.collection_name)\n",
    "            print(f\"Collection '{self.collection_name}' initialized successfully.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing ChromaDB client: {e}\")\n",
    "    \n",
    "    def add_embeddings(self, texts: List[Any], embeddings: np.ndarray):\n",
    "        if not self.collection:\n",
    "            raise ValueError(\"Collection is not initialized.\")\n",
    "        \n",
    "        if len(texts) != len(embeddings):\n",
    "            raise ValueError(\"Number of texts and embeddings must match.\")\n",
    "        \n",
    "        print(f\"Adding {len(texts)} embeddings to vector store'...\")\n",
    "\n",
    "        ids = [str(i) for i in range(len(texts))]\n",
    "        metadatas = []\n",
    "        contents = []\n",
    "        embeddings_lists = []\n",
    "\n",
    "        for i, (doc, embedding) in enumerate(zip(texts, embeddings)):\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadatas.append(metadata)\n",
    "            contents.append(doc.page_content)\n",
    "            embeddings_lists.append(embedding.tolist())\n",
    "\n",
    "        try:\n",
    "            self.collection.add(ids=ids, documents=contents, metadata=metadatas, embeddings=embeddings_lists)\n",
    "            print(f\"Added {len(texts)} embeddings to the collection '{self.collection_name}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding embeddings to collection: {e}\")\n",
    "\n",
    "vector_store = VectorStore()\n",
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec57e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = [chunk.page_content for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9456bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_manager.embed_texts(content)\n",
    "\n",
    "vector_store.add_embeddings(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15610a0d",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7876438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager, top_k: int = 5):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def retrieve(self, query: str) -> List[Any]:\n",
    "        print(f\"Retrieving top {self.top_k} documents for query: '{query}'\")\n",
    "\n",
    "        query_embedding = self.embedding_manager.embed_texts([query])[0]\n",
    "        \n",
    "        results = self.vector_store.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=self.top_k\n",
    "        )\n",
    "        \n",
    "        retrieved_context = []\n",
    "        for doc_content, metadata in zip(results['documents'][0], results['metadatas'][0]):\n",
    "            retrieved_context.append({'content': doc_content, 'metadata': metadata})\n",
    "        \n",
    "        return retrieved_context\n",
    "\n",
    "retriever = Retriever(vector_store, embedding_manager, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", max_tokens=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df3b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query: str, retriever, llm, top_k=3) -> str:\n",
    "    retrieved_docs = retriever.retrieve(query)\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc['content'] for doc in retrieved_docs])\n",
    "    \n",
    "    if not context:\n",
    "        return \"No relevant information found to answer the question. Re-Phrase it!\"\n",
    "    \n",
    "    prompt = f\"Using the following context, answer the question:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    \n",
    "    print(\"Generating answer using LLM...\")\n",
    "    answer = llm.invoke([prompt.format(context=context, query=query)])\n",
    "    \n",
    "    return answer.content\n",
    "\n",
    "\n",
    "res = generate_answer(\"What is the pdf about?\", retriever, llm, top_k=3)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fd71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
